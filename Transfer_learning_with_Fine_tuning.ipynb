{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "authorship_tag": "ABX9TyNK2QIxybR+Fj1mf5KjcPK6",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/rvishakhs/Deep_Learning/blob/Fundamentals/Transfer_learning_with_Fine_tuning.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "b3FVBINed4bK",
        "outputId": "5d1c88f6-8981-4d38-e904-cd47ab76e34d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/bin/bash: line 1: nvidia-smi: command not found\n"
          ]
        }
      ],
      "source": [
        "!nvidia-smi"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!wget https://raw.githubusercontent.com/rvishakhs/tensorflow-deep-learning/refs/heads/main/extras/helper_functions.py\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oi6IULdieJ7-",
        "outputId": "810811fd-73c5-4205-e6ff-a651d1789663"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2025-01-29 13:37:40--  https://raw.githubusercontent.com/rvishakhs/tensorflow-deep-learning/refs/heads/main/extras/helper_functions.py\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.108.133, 185.199.109.133, 185.199.110.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.108.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 10246 (10K) [text/plain]\n",
            "Saving to: ‘helper_functions.py’\n",
            "\n",
            "helper_functions.py 100%[===================>]  10.01K  --.-KB/s    in 0s      \n",
            "\n",
            "2025-01-29 13:37:41 (89.7 MB/s) - ‘helper_functions.py’ saved [10246/10246]\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# @title Default title text\n",
        "from helper_functions import create_tensorboard_callback, plot_loss_curves, unzip_data, walk_through_dir"
      ],
      "metadata": {
        "id": "grlFeEpTfJ_i"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Get the data Ready\n",
        "!wget https://storage.googleapis.com/ztm_tf_course/food_vision/10_food_classes_10_percent.zip\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "icuseTXojwnx",
        "outputId": "525f6524-e26a-4d9c-d14c-34b5dc229cfb"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2025-01-29 13:37:55--  https://storage.googleapis.com/ztm_tf_course/food_vision/10_food_classes_10_percent.zip\n",
            "Resolving storage.googleapis.com (storage.googleapis.com)... 142.251.184.207, 74.125.126.207, 74.125.132.207, ...\n",
            "Connecting to storage.googleapis.com (storage.googleapis.com)|142.251.184.207|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 168546183 (161M) [application/zip]\n",
            "Saving to: ‘10_food_classes_10_percent.zip’\n",
            "\n",
            "10_food_classes_10_ 100%[===================>] 160.74M   176MB/s    in 0.9s    \n",
            "\n",
            "2025-01-29 13:37:56 (176 MB/s) - ‘10_food_classes_10_percent.zip’ saved [168546183/168546183]\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "unzip_data('10_food_classes_10_percent.zip')"
      ],
      "metadata": {
        "id": "fTI0nmwtfc0C"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "23H75wLLRQ6E"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "JK1N73jhQr5i"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "walk_through_dir('/content/10_food_classes_10_percent')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fnLM4sOkj7yz",
        "outputId": "a6c2c286-7875-4917-8c66-4c3bbfe84a8a"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "There are 2 directories and 0 images in '/content/10_food_classes_10_percent'.\n",
            "There are 10 directories and 0 images in '/content/10_food_classes_10_percent/train'.\n",
            "There are 0 directories and 75 images in '/content/10_food_classes_10_percent/train/steak'.\n",
            "There are 0 directories and 75 images in '/content/10_food_classes_10_percent/train/ice_cream'.\n",
            "There are 0 directories and 75 images in '/content/10_food_classes_10_percent/train/chicken_curry'.\n",
            "There are 0 directories and 75 images in '/content/10_food_classes_10_percent/train/hamburger'.\n",
            "There are 0 directories and 75 images in '/content/10_food_classes_10_percent/train/chicken_wings'.\n",
            "There are 0 directories and 75 images in '/content/10_food_classes_10_percent/train/pizza'.\n",
            "There are 0 directories and 75 images in '/content/10_food_classes_10_percent/train/fried_rice'.\n",
            "There are 0 directories and 75 images in '/content/10_food_classes_10_percent/train/grilled_salmon'.\n",
            "There are 0 directories and 75 images in '/content/10_food_classes_10_percent/train/sushi'.\n",
            "There are 0 directories and 75 images in '/content/10_food_classes_10_percent/train/ramen'.\n",
            "There are 10 directories and 0 images in '/content/10_food_classes_10_percent/test'.\n",
            "There are 0 directories and 250 images in '/content/10_food_classes_10_percent/test/steak'.\n",
            "There are 0 directories and 250 images in '/content/10_food_classes_10_percent/test/ice_cream'.\n",
            "There are 0 directories and 250 images in '/content/10_food_classes_10_percent/test/chicken_curry'.\n",
            "There are 0 directories and 250 images in '/content/10_food_classes_10_percent/test/hamburger'.\n",
            "There are 0 directories and 250 images in '/content/10_food_classes_10_percent/test/chicken_wings'.\n",
            "There are 0 directories and 250 images in '/content/10_food_classes_10_percent/test/pizza'.\n",
            "There are 0 directories and 250 images in '/content/10_food_classes_10_percent/test/fried_rice'.\n",
            "There are 0 directories and 250 images in '/content/10_food_classes_10_percent/test/grilled_salmon'.\n",
            "There are 0 directories and 250 images in '/content/10_food_classes_10_percent/test/sushi'.\n",
            "There are 0 directories and 250 images in '/content/10_food_classes_10_percent/test/ramen'.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Create training and test directory paths\n",
        "\n",
        "train_dir = '/content/10_food_classes_10_percent/train'\n",
        "test_dir = '/content/10_food_classes_10_percent/test'"
      ],
      "metadata": {
        "id": "uq4aeGKtkac4"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "IMG_SIZE = (224, 224)\n",
        "BATCH_SIZE = 32\n",
        "train_data = tf.keras.preprocessing.image_dataset_from_directory(directory=train_dir,\n",
        "                                                                 image_size=IMG_SIZE,\n",
        "                                                                 batch_size=BATCH_SIZE,\n",
        "                                                                 label_mode='categorical')\n",
        "test_data = tf.keras.preprocessing.image_dataset_from_directory(directory=test_dir,\n",
        "                                                                 image_size=IMG_SIZE,\n",
        "                                                                 batch_size=BATCH_SIZE,\n",
        "                                                                 label_mode='categorical')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EgS_MPEllibK",
        "outputId": "c256b8a7-8648-4370-cdb3-c3874896134a"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 750 files belonging to 10 classes.\n",
            "Found 2500 files belonging to 10 classes.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train_data\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "S7EtlCFdkJab",
        "outputId": "55a1e317-e68e-4b8c-bc5c-7053a1a9641a"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<_PrefetchDataset element_spec=(TensorSpec(shape=(None, 224, 224, 3), dtype=tf.float32, name=None), TensorSpec(shape=(None, 10), dtype=tf.float32, name=None))>"
            ]
          },
          "metadata": {},
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Building a transfer learning model with functional api tensorflow\n",
        "# 1. Create base model with tf.keras.applications\n",
        "base_model = tf.keras.applications.EfficientNetB0(include_top=False)\n",
        "\n",
        "# 2. Free the base model ( so the underlying pre-trained patterns aren't updated)\n",
        "base_model.trainable = False\n",
        "\n",
        "# 3. Create inputs into our model\n",
        "inputs = tf.keras.layers.Input(shape=(224, 224, 3), name='Input_layer')\n",
        "\n",
        "# 4. Pass the inputs to the base_model\n",
        "x = base_model(inputs)\n",
        "print(f'Shape after passing inputs through the base model: {x.shape}')\n",
        "\n",
        "# 5. Average pool the outputs of the basemodel (aggregate ball the most important information, reduce number of computations)\n",
        "x = tf.keras.layers.GlobalAveragePooling2D(name='global_average_pooling_layer')(x)\n",
        "print(f'Shape after GlobalAveragePooling2D: {x.shape}')\n",
        "\n",
        "# 6. Create the output activation layer\n",
        "outputs = tf.keras.layers.Dense(10, activation='softmax', name='output_layer')(x)\n",
        "\n",
        "# 7. Combine the inputs with the output into a model\n",
        "model_0 = tf.keras.Model(inputs, outputs)\n",
        "\n",
        "# 9. Compile for the model\n",
        "model_0.compile(loss='categorical_crossentropy',\n",
        "                optimizer=tf.keras.optimizers.Adam(),\n",
        "                metrics=['accuracy']\n",
        "                )\n",
        "\n",
        "history_0 = model_0.fit(train_data,\n",
        "            epochs=5,\n",
        "            steps_per_epoch=len(train_data) // 32,\n",
        "            validation_data=test_data,\n",
        "            validation_steps=int(0.25 * len(test_data) // 32),\n",
        "            callbacks=[create_tensorboard_callback(dir_name='transfer_learning',\n",
        "                                                   experiment_name='10_percentage_data')])"
      ],
      "metadata": {
        "id": "FfYPtvfRnS2F"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model_0.summary()"
      ],
      "metadata": {
        "id": "kay8omjk2HfO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# check out our model loss function\n",
        "plot_loss_curves(history_0)"
      ],
      "metadata": {
        "id": "3Qi1P3jh3y7y"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Model 2 fetaure extraction transfer learning and data augmentation in place\n",
        "# Get the data Ready\n",
        "#!wget https://storage.googleapis.com/ztm_tf_course/food_vision/10_food_classes_10_percent.zip"
      ],
      "metadata": {
        "id": "M_siSgF84Jyk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Seting up train and test dir\n",
        "train_dir_aug = '/content/10_food_classes_10_percent/train'\n",
        "test_dir_aug = '/content/10_food_classes_10_percent/test'"
      ],
      "metadata": {
        "id": "-068PdMqpvUl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Set data inputs\n",
        "\n",
        "import tensorflow as tf\n",
        "IMG_SIZE = (224, 224)\n",
        "BATCH_SIZE = 32\n",
        "\n",
        "train_data_10_percentage = tf.keras.preprocessing.image_dataset_from_directory(train_dir_aug,\n",
        "                                                                               label_mode='categorical',\n",
        "                                                                               batch_size=BATCH_SIZE,\n",
        "                                                                               image_size=IMG_SIZE)\n",
        "test_data_10_percentage = tf.keras.preprocessing.image_dataset_from_directory(test_dir_aug,\n",
        "                                                                               label_mode='categorical',\n",
        "                                                                               batch_size=BATCH_SIZE,\n",
        "                                                                               image_size=IMG_SIZE)"
      ],
      "metadata": {
        "id": "6L5_N4JYp8Mw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Creatinig a data augmentation layer with seqential api\n",
        "\n",
        "from tensorflow.keras import layers\n",
        "#from tensorflow.keras.layers.experimental import preprocessing\n",
        "from tensorflow.keras.models import Sequential\n",
        "\n",
        "data_augmentation = Sequential([\n",
        "    layers.RandomFlip('horizontal'),\n",
        "    layers.RandomHeight(0.2),\n",
        "    layers.RandomWidth(0.2),\n",
        "    layers.RandomZoom(0.2),\n",
        "    layers.RandomRotation(0.2)\n",
        "   #Layers.Rescaling(1./255) #if we are using ResNet or other models which requires scaled values\n",
        "], name='data_augmentation')\n",
        "\n"
      ],
      "metadata": {
        "id": "ww5joPTnqqzG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# setup the input shape to our model\n",
        "input_shape = (224, 224, 3)\n",
        "\n",
        "# Create a frozen basemodel\n",
        "base_model = tf.keras.applications.EfficientNetB1(include_top=False)\n",
        "base_model.trainable = False\n",
        "\n",
        "# Create the input and output layers (include the layers between)\n",
        "inputs = layers.Input(shape=input_shape, name='input_layer')\n",
        "\n",
        "# Passing the input layer to the data augmentation layer we created above\n",
        "x = data_augmentation(inputs)  #Augmenting our training images\n",
        "\n",
        "# Passing the augmented data into our base model and keep the training mode off\n",
        "x = base_model(x, training=False)\n",
        "\n",
        "# Passing to the pooling layer for feature extraction\n",
        "x = layers.GlobalAveragePooling2D(name='global_average_pooling_layer')(x)\n",
        "\n",
        "# Creating the output layer and passing the x to it\n",
        "outputs = layers.Dense(10, activation='softmax', name='output_layer')(x)\n",
        "\n",
        "# Build the model\n",
        "model_2 = tf.keras.Model(inputs, outputs)\n",
        "\n",
        "# Compile the model\n",
        "model_2.compile(loss='categorical_crossentropy',\n",
        "                optimizer=tf.keras.optimizers.Adam(),\n",
        "                metrics=['accuracy'])\n",
        "\n",
        "# Fit the model\n",
        "history_2 = model_2.fit(train_data_10_percentage,\n",
        "                        epochs=5,\n",
        "                        steps_per_epoch= len(train_data_10_percentage) // 32,\n",
        "                        validation_data=test_data_10_percentage,\n",
        "                        validation_steps=int(0.25 * len(test_data_10_percentage) // 32),\n",
        "                        callbacks=[create_tensorboard_callback(dir_name='transfer_learning',\n",
        "                                                   experiment_name='10_percentage_data_augmented')])"
      ],
      "metadata": {
        "id": "nNwtFTFYt7SX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Create a model checkpoint call back\n",
        "checkpoint_path = 'ten_percentage_model_checkpoint/checkpoint.ckpt'\n",
        "checkpoint_callback = tf.keras.callbacks.ModelCheckpoint(filepath=checkpoint_path,\n",
        "                                                         save_best_only=False,\n",
        "                                                         save_weights_only=True,\n",
        "                                                         save_freq='epoch',\n",
        "                                                         verbose=1)\n"
      ],
      "metadata": {
        "id": "0zui2IvfrVRq"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}